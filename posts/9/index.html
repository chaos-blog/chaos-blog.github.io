<!DOCTYPE html>
<html lang="en">
<head>
  
    <title>Pytorch使用单机多卡训练 :: Chaos</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="需求 对基于pytorch的深度学习模型进行多卡训练以加速训练过程 由于显卡版本过于老旧，安装配置NCCL工程量过于庞大，希望使用简单的pytorch代码实现单机多卡训练，不考虑多机多卡的显卡通信 训练完成后保存的checkpoint需要能够在任何设备上进行加载、推理 实现 训练 pytorch提供了简单的单机多卡训练api，只需要在初始化模型之后执行下列语句将模型复制到多卡上 # initiate multi-gpu training model = nn.DataParallel(model, device_ids=&amp;lt;ids of the gpus you want to use&amp;gt;) 其他操作与单卡训练完全一致 加载checkpoint 上述操作后保存的checkpoint如果按照常规方法直接进行加载会报错 RuntimeError: Error(s) in loading state_dict for &amp;lt;ModelName&amp;gt;: Missing key(s) in state_dict:... debug遍历后发现其实其状态字典是完全一致的，只是因为我们在训练过程中将模型定义为了多卡并行模型。这里只需要按照训练过程中转换为多卡模型的代码初始化当前模型结构即可，即执行： # initiate multi-gpu training model = nn.DataParallel(model, device_ids=&amp;lt;ids of the gpus you want to use&amp;gt;) 其他操作与征程推理完全一致，若不想使用多卡/只想使用cpu，只需要按照常规将device = torch.device(&amp;quot;&amp;lt;cpu/cuda:id&amp;gt;&amp;quot;)即可 Note：查阅资料过程中发现有解答建议使用参数强行忽略模型加载的错误torch.load(&amp;lt;checkpoint&amp;gt;, strict=False)，经测试，这样加载的模型啥也不是&amp;hellip;不知道为什么pytorch官方要提供这个接口" />
<meta name="keywords" content="" />

  <meta name="robots" content="noodp" />

<link rel="canonical" href="/posts/9/" />






  
  
  
  
  
  <link rel="stylesheet" href="/styles.css">







  <link rel="shortcut icon" href="/img/theme-colors/blue.png">
  <link rel="apple-touch-icon" href="/img/theme-colors/blue.png">



<meta name="twitter:card" content="summary" />

  
    <meta name="twitter:site" content="" />
  
    <meta name="twitter:creator" content="chaos" />



<meta property="og:locale" content="en" />
<meta property="og:type" content="article" />
<meta property="og:title" content="Pytorch使用单机多卡训练">
<meta property="og:description" content="需求 对基于pytorch的深度学习模型进行多卡训练以加速训练过程 由于显卡版本过于老旧，安装配置NCCL工程量过于庞大，希望使用简单的pytorch代码实现单机多卡训练，不考虑多机多卡的显卡通信 训练完成后保存的checkpoint需要能够在任何设备上进行加载、推理 实现 训练 pytorch提供了简单的单机多卡训练api，只需要在初始化模型之后执行下列语句将模型复制到多卡上 # initiate multi-gpu training model = nn.DataParallel(model, device_ids=&amp;lt;ids of the gpus you want to use&amp;gt;) 其他操作与单卡训练完全一致 加载checkpoint 上述操作后保存的checkpoint如果按照常规方法直接进行加载会报错 RuntimeError: Error(s) in loading state_dict for &amp;lt;ModelName&amp;gt;: Missing key(s) in state_dict:... debug遍历后发现其实其状态字典是完全一致的，只是因为我们在训练过程中将模型定义为了多卡并行模型。这里只需要按照训练过程中转换为多卡模型的代码初始化当前模型结构即可，即执行： # initiate multi-gpu training model = nn.DataParallel(model, device_ids=&amp;lt;ids of the gpus you want to use&amp;gt;) 其他操作与征程推理完全一致，若不想使用多卡/只想使用cpu，只需要按照常规将device = torch.device(&amp;quot;&amp;lt;cpu/cuda:id&amp;gt;&amp;quot;)即可 Note：查阅资料过程中发现有解答建议使用参数强行忽略模型加载的错误torch.load(&amp;lt;checkpoint&amp;gt;, strict=False)，经测试，这样加载的模型啥也不是&amp;hellip;不知道为什么pytorch官方要提供这个接口" />
<meta property="og:url" content="/posts/9/" />
<meta property="og:site_name" content="Chaos" />

  
    <meta property="og:image" content="/img/favicon/blue.png">
  

<meta property="og:image:width" content="1200">
<meta property="og:image:height" content="627">













</head>
<body class="blue">


<div class="container center headings--one-size">

  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="/">
  <div class="logo">
    Square-one
  </div>
</a>

    </div>
    
      <ul class="menu menu--mobile">
  <li class="menu__trigger">Menu&nbsp;▾</li>
  <li>
    <ul class="menu__dropdown">
      
        
          <li><a href="posts/about">About</a></li>
        
      
      
    </ul>
  </li>
</ul>

    
    
  </div>
  
    <nav class="navigation-menu">
  <ul class="navigation-menu__inner menu--desktop">
    
      
        
          <li><a href="posts/about" >About</a></li>
        
      
      
    
  </ul>
</nav>

  
</header>


  <div class="content">
    
<article class="post">
  <h1 class="post-title">
    <a href="/posts/9/">Pytorch使用单机多卡训练</a>
  </h1>
  <div class="post-meta">
    
    
      <span class="post-author">chaos</span>
    
    
      <span class="post-reading-time">:: 1 min read (57 words)</span>
    
  </div>

  
    <span class="post-tags">
      
      #<a href="/tags/python/">Python</a>&nbsp;
      
      #<a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>&nbsp;
      
    </span>
  
  


  
    <div class="table-of-contents">
      <h2>
        目录
      </h2>
      <nav id="TableOfContents">
  <ul>
    <li><a href="#需求">需求</a></li>
    <li><a href="#实现">实现</a>
      <ul>
        <li><a href="#训练">训练</a></li>
        <li><a href="#加载checkpoint">加载checkpoint</a></li>
      </ul>
    </li>
  </ul>
</nav>
    </div>
  

  <div class="post-content"><div>
        <h2 id="需求">需求<a href="#需求" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h2>
<ul>
<li>对基于pytorch的深度学习模型进行多卡训练以加速训练过程</li>
<li>由于显卡版本过于老旧，安装配置NCCL工程量过于庞大，希望使用简单的pytorch代码实现单机多卡训练，不考虑多机多卡的显卡通信</li>
<li>训练完成后保存的checkpoint需要能够在任何设备上进行加载、推理</li>
</ul>
<h2 id="实现">实现<a href="#实现" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h2>
<h3 id="训练">训练<a href="#训练" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h3>
<ul>
<li>pytorch提供了简单的单机多卡训练api，只需要在初始化模型之后执行下列语句将模型复制到多卡上</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># initiate multi-gpu training</span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>DataParallel(model, device_ids<span style="color:#f92672">=&lt;</span>ids of the gpus you want to use<span style="color:#f92672">&gt;</span>)
</span></span></code></pre></div><ul>
<li>其他操作与单卡训练完全一致</li>
</ul>
<h3 id="加载checkpoint">加载checkpoint<a href="#加载checkpoint" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h3>
<ul>
<li>上述操作后保存的checkpoint如果按照常规方法直接进行加载会报错</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#a6e22e">RuntimeError</span>: Error(s) <span style="color:#f92672">in</span> loading state_dict <span style="color:#66d9ef">for</span> <span style="color:#f92672">&lt;</span>ModelName<span style="color:#f92672">&gt;</span>:
</span></span><span style="display:flex;"><span>	Missing key(s) <span style="color:#f92672">in</span> state_dict:<span style="color:#f92672">...</span>
</span></span></code></pre></div><ul>
<li>debug遍历后发现其实其状态字典是完全一致的，只是因为我们在训练过程中将模型定义为了多卡并行模型。这里只需要按照训练过程中转换为多卡模型的代码初始化当前模型结构即可，即执行：</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># initiate multi-gpu training</span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>DataParallel(model, device_ids<span style="color:#f92672">=&lt;</span>ids of the gpus you want to use<span style="color:#f92672">&gt;</span>)
</span></span></code></pre></div><ul>
<li>其他操作与征程推理完全一致，若不想使用多卡/只想使用cpu，只需要按照常规将<code>device = torch.device(&quot;&lt;cpu/cuda:id&gt;&quot;)</code>即可</li>
</ul>
<p><strong>Note：查阅资料过程中发现有解答建议使用参数强行忽略模型加载的错误<code>torch.load(&lt;checkpoint&gt;, strict=False)</code>，经测试，这样加载的模型啥也不是&hellip;不知道为什么pytorch官方要提供这个接口</strong></p>

      </div></div>

  
    
<div class="pagination">
    <div class="pagination__title">
        <span class="pagination__title-h">Read other posts</span>
        <hr />
    </div>
    <div class="pagination__buttons">
        
        <span class="button previous">
            <a href="/posts/6/">
                <span class="button__icon">←</span>
                <span class="button__text">python中的print()函数深度使用</span>
            </a>
        </span>
        
        
        <span class="button next">
            <a href="/posts/20/">
                <span class="button__text">Pytorch单机多卡(DP)训练之后的模型“货不对板”</span>
                <span class="button__icon">→</span>
            </a>
        </span>
        
    </div>
</div>

  

  
    

  
</article>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright">
        <span>© 2023 Powered by <a href="http://gohugo.io">Hugo</a></span>
    
      <span>:: <a href="https://github.com/panr/hugo-theme-terminal" target="_blank">Theme</a> made by <a href="https://github.com/panr" target="_blank">panr</a></span>
      </div>
  </div>
</footer>






<script type="text/javascript" src="/bundle.min.js"></script>





  
</div>

</body>
</html>
